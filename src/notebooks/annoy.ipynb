{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931295ca-c625-4bd7-a7af-acb214592092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow \n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "import datetime\n",
    "from annoy import AnnoyIndex\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ec8457-1027-4ade-95fe-e5ab2a3706b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank = 1\n",
    "n_trees = [10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec94e1d6-ccc8-4f4c-86d1-2a5d6c737031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read success\n"
     ]
    }
   ],
   "source": [
    "items = \"asl-matrix_i.parquet\"\n",
    "users = \"asl-matrix_u.parquet\"\n",
    "train_gt = \"asl-train_gt_small.parquet\"\n",
    "val_gt = \"asl-val_gt_small.parquet\"\n",
    "test_gt = \"asl-test_gt.parquet\"\n",
    "items_dd = dd.read_parquet(items, engine = 'pyarrow')\n",
    "users_dd = dd.read_parquet(users, engine='pyarrow')\n",
    "train_gt_dd = dd.read_parquet(train_gt, engine='pyarrow')\n",
    "val_gt_dd = dd.read_parquet(val_gt, engine='pyarrow')\n",
    "test_gt_dd = dd.read_parquet(test_gt, engine='pyarrow')\n",
    "print('read success')\n",
    "items = items_dd.compute()\n",
    "users = users_dd.compute()\n",
    "train_gt = train_gt_dd.compute()\n",
    "val_gt = val_gt_dd.compute()\n",
    "test_gt = test_gt_dd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d751717-9391-4ea2-84c0-28b1130ebc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_precision(rec, gt):\n",
    "    '''\n",
    "    rec : recommendation list for one user\n",
    "    gt : ground truth for one user\n",
    "    '''\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,item in enumerate(rec):\n",
    "        if item in gt:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "    \n",
    "    return score / num_hits if num_hits != 0.0 else 0.0\n",
    "\n",
    "def evaluation(rec, gt):\n",
    "    '''\n",
    "    rec : dataframe\n",
    "    gt : dataframe\n",
    "    '''\n",
    "    df = pd.merge(rec, gt, how='inner', on='user_id')\n",
    "    score = [average_precision(df['pred'][i], df['gt'][i]) for i in range(len(df))]\n",
    "    return np.array(score).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03c1ca8-ac2d-4bba-9b2b-a0e9910b1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.583955764770508\n",
      "n_tree: 10 search_k: 1000\n",
      "train map: 0.000767 val map: 0.000496 test map: 0.004759\n",
      "time: 27.227941036224365\n",
      "n_tree: 10 search_k: 5000\n",
      "train map: 0.002366 val map: 0.001513 test map: 0.004627\n",
      "time: 31.41845417022705\n",
      "n_tree: 20 search_k: 2000\n",
      "train map: 0.001256 val map: 0.000664 test map: 0.001274\n",
      "time: 50.62485313415527\n",
      "n_tree: 20 search_k: 10000\n",
      "train map: 0.001496 val map: 0.001037 test map: 0.000822\n"
     ]
    }
   ],
   "source": [
    "for tree in n_trees:\n",
    "    for k in [tree * 100, tree * 100 * 5]:\n",
    "        pred = {}\n",
    "        f = rank  # Length of item vector that will be indexed\n",
    "        t = AnnoyIndex(f, 'dot')\n",
    "        for index, row in items.iterrows():\n",
    "            t.add_item(row['id'], row['features'])\n",
    "        \n",
    "        s = time.time()\n",
    "        t.build(tree) # 10 trees\n",
    "        t.save('test.ann')\n",
    "        u = AnnoyIndex(f, 'dot')\n",
    "        u.load('test.ann') # super fast, will just mmap the file\n",
    "        for index, row in users.iterrows():\n",
    "            pred[row['id']] = u.get_nns_by_vector(row['features'], 100, search_k=k, include_distances=False)\n",
    "        e = time.time()\n",
    "        print(\"time: {}\".format(e-s))\n",
    "        \n",
    "        pred_df = pd.DataFrame(list(pred.items()), columns=['user_id', 'pred'])\n",
    "        train_map = evaluation(pred_df,train_gt) \n",
    "        val_map = evaluation(pred_df,val_gt)\n",
    "        test_map = evaluation(pred_df,test_gt)\n",
    "        print(\"n_tree: {} search_k: {}\".format(tree, k))\n",
    "        print(\"train map: {} val map: {} test map: {}\".format(round(train_map,6), round(val_map,6), round(test_map,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a56379-c1d6-4567-90a5-1ff8f67d023b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a181fdf-d040-4d85-a2a3-2665dde8e876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
